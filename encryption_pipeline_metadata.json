{
  "name": "Data encryption pipeline",
  "description": "Encrypt data from different sources using DLP or Tink.",
  "parameters": [
    {
      "name": "schema",
      "label": "Data's AVRO Schema",
      "helpText": "The data source's AVRO schema JSON"
    },
    {
      "name": "tokenizeColumns",
      "label": "Columns to tokenize",
      "helpText": "The list of columns based on schema to tokenize. Format: $.columnName",
      "isOptional": true
    },
    {
      "name": "outputDirectory",
      "label": "Output GCS directory",
      "helpText": "The GCS folder to output the tokenized AVRO file. One of the outputDirectory or outputBigQueryTable needs to be provided",
      "isOptional": true
    },
    {
      "name": "outputBigQueryTable",
      "label": "Output BigQuery Table",
      "helpText": "The BigQuery table to output the tokenized data. One of the outputDirectory or outputBigQueryTable needs to be provided",
      "isOptional": true
    },
    {
      "name": "bigQueryAppend",
      "label": "BigQuery Append",
      "helpText": "flag to enable appending into output BigQuery table. Default false",
      "isOptional": true
    },
    {
      "name": "tinkEncryptionKeySetJson",
      "label": "TINK Encryption Keyset JSON",
      "helpText": "The Wrapped TINK encryption key to tokenize the data. Provide one of tinkEncryptionKeySetJson or dlpEncryptConfigJson",
      "isOptional": true
    },
    {
      "name": "mainKmsKeyUri",
      "label": "KMS Key-Encryption-Key",
      "helpText": "The wrapper key that was used for encrypting the TINK key",
      "isOptional": true
    },
    {
      "name": "dlpEncryptConfigJson",
      "label": "DLP Encryption Config JSON",
      "helpText": "Provide one of tinkEncryptionKeySetJson or dlpEncryptConfigJson",
      "isOptional": true
    },
    {
      "name": "valueTokenizerFactoryFullClassName",
      "label": "Value Tokenizer",
      "helpText": "Custom Value tokenizer factory class. The custom value tokenizer encrypts your data.",
      "isOptional": true
    },
    {
      "name": "keyMaterial",
      "label": "Key Material",
      "helpText": "String representing encryption key options. DLP config JSON, TINK JSON, etc.",
      "isOptional": true
    },
    {
      "name": "keyMaterialType",
      "label": "Key Material Type",
      "helpText": "The type of key material for encryption. One of: [TINK_GCP_KEYSET_JSON, RAW_BASE64_KEY, RAW_UTF8_KEY, GCP_KMS_WRAPPED_KEY, GCP_SECRET_KEY]",
      "isOptional": true
    },
    {
      "name": "sourceType",
      "label": "Data source type",
      "helpText": "The data source to analyse/inspect. One of: [AVRO, PARQUET, BIGQUERY_TABLE, BIGQUERY_QUERY, JDBC_TABLE, JDBC_QUERY, CSV_FILE]"
    },
    {
      "name": "inputPattern",
      "label": "Date Source",
      "helpText": "The location of the datasource: for AVRO or PARQUET, the GCS file pattern to use as input, for BIGQUERY_TABLE: a Fully Qualified table name as {projectId}:{datasetId}.{tableId} format, for JDBC_TABLE, the name of the table. For JDBC_QUERY, a SELECT query to run on the target."
    },
    {
      "name": "dlpRegion",
      "label": "DLP Region",
      "helpText": "The DLP region to use, default: global",
      "isOptional": true
    },
    {
      "name": "csvHeaders",
      "label": "The Headers to use for CSV file inputs",
      "helpText": "One of csvHeaders or csvFirstRowHeader is required if sourceType=CSV_FILE",
      "isOptional": true
    },
    {
      "name": "csvFirstRowHeader",
      "label": "Use CSV First Row as header",
      "helpText": "One of csvHeaders or csvFirstRowHeader is required if sourceType=CSV_FILE",
      "isOptional": true
    },
    {
      "name": "csvCharset",
      "label": "Charset to use for CSV files",
      "helpText": "default: UTF-8",
      "isOptional": true
    },
    {
      "name": "csvColumnDelimiter",
      "label": "Column delimiter for CSV",
      "helpText": "default: ','",
      "isOptional": true
    },
    {
      "name": "csvFormatType",
      "label": "CSV Format type supported by Apache Commons CSV",
      "helpText": "CSV Format type supported by Apache Commons CSV default: Default",
      "isOptional": true
    },
    {
      "name": "jdbcConnectionUrl",
      "label": "JDBC Connection URL",
      "helpText": "The Connection URL used for connecting to a SQL datasource using JDBC. (Required when sourceType=JDBC_TABLE)",
      "isOptional": true
    },
    {
      "name": "jdbcDriverClass",
      "label": "JDBC Driver class name",
      "helpText": "The JDBC driver to use for reading from SQL datasource. (Required when sourceType=JDBC_TABLE)",
      "isOptional": true
    },
    {
      "name": "jdbcFilterClause",
      "label": "JDBC Filter clause",
      "helpText": "The WHERE clause to filter records for inspection from JDBC source. (Optional, though Recommended when sourceType=JDBC_TABLE)",
      "isOptional": true
    },
    {
      "name": "jdbcUserName",
      "label": "JDBC Connection Username",
      "helpText": "The username for the database connection. (Required when sourceType=JDBC_TABLE)",
      "isOptional": true
    },
    {
      "name": "jdbcPasswordSecretsKey",
      "label": "Cloud Secret Version Id that stores JDBC password",
      "helpText": "The Cloud Secrets version that stores password for the user-name. (One of jdbcPassword or jdbcPasswordSecretsKey required when sourceType=JDBC_TABLE)",
      "isOptional": true
    },
    {
      "name": "jdbcPassword",
      "label": "Plain-text password for the JDBC user",
      "helpText": "The plain-text password for the user-name. (One of jdbcPassword or jdbcPasswordSecretsKey required when sourceType=JDBC_TABLE)",
      "isOptional": true
    }
  ]
}
